{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lstm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "lr = 1e-3\n",
    "running_loss = []\n",
    "BATCH_SIZE = 32\n",
    "logs_per_epoch = 10\n",
    "num_epochs = 14\n",
    "PAD_BATCH_FLAG = True\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "json_file = '/home/asilva/Data/yelp_dataset_2017/review.json'\n",
    "train_percent = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = lstm_utils.load_yelp_data(json_file)\n",
    "dataset, test_dataset, word_to_id = lstm_utils.build_dataset_yelp(raw_data, train_percent)\n",
    "vocab = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "test_dataset.sort(key=lambda x: len(x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lstm_utils.clean_dataset(dataset)\n",
    "test_dataset = lstm_utils.clean_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_ones = 0\n",
    "num_twos = 0\n",
    "num_threes = 0\n",
    "num_fours = 0\n",
    "num_fives = 0\n",
    "lengths = []\n",
    "for point in dataset:\n",
    "    rating = point[1][0]\n",
    "    lengths.append(len(point[0]))\n",
    "    if rating == 0:\n",
    "        num_ones += 1.0\n",
    "    elif rating == 1:\n",
    "        num_twos += 1.0\n",
    "    elif rating == 2:\n",
    "        num_threes += 1.0\n",
    "    elif rating == 3:\n",
    "        num_fours += 1.0\n",
    "    elif rating == 4:\n",
    "        num_fives += 1.0\n",
    "perc_ones = 100*(num_ones/len(dataset))\n",
    "perc_twos = 100*(num_twos/len(dataset))\n",
    "perc_threes = 100*(num_threes/len(dataset))\n",
    "perc_fours = 100*(num_fours/len(dataset))\n",
    "perc_fives = 100*(num_fives/len(dataset))\n",
    "print(\"Percent 1:\", perc_ones)\n",
    "print(\"Percent 2:\", perc_twos)\n",
    "print(\"Percent 3:\", perc_threes)\n",
    "print(\"Percent 4:\", perc_fours)\n",
    "print(\"Percent 5:\", perc_fives)\n",
    "lengths = np.array(lengths)\n",
    "print(\"Mean length:\", np.mean(lengths))\n",
    "print(\"Stddev length:\", np.std(lengths))\n",
    "\n",
    "\n",
    "num_ones = 0\n",
    "num_twos = 0\n",
    "num_threes = 0\n",
    "num_fours = 0\n",
    "num_fives = 0\n",
    "lengths = []\n",
    "for point in test_dataset:\n",
    "    rating = point[1][0]\n",
    "    lengths.append(len(point[0]))\n",
    "    if rating == 0:\n",
    "        num_ones += 1.0\n",
    "    elif rating == 1:\n",
    "        num_twos += 1.0\n",
    "    elif rating == 2:\n",
    "        num_threes += 1.0\n",
    "    elif rating == 3:\n",
    "        num_fours += 1.0\n",
    "    elif rating == 4:\n",
    "        num_fives += 1.0\n",
    "perc_ones = 100*(num_ones/len(test_dataset))\n",
    "perc_twos = 100*(num_twos/len(test_dataset))\n",
    "perc_threes = 100*(num_threes/len(test_dataset))\n",
    "perc_fours = 100*(num_fours/len(test_dataset))\n",
    "perc_fives = 100*(num_fives/len(test_dataset))\n",
    "print(\"Percent 1:\", perc_ones)\n",
    "print(\"Percent 2:\", perc_twos)\n",
    "print(\"Percent 3:\", perc_threes)\n",
    "print(\"Percent 4:\", perc_fours)\n",
    "print(\"Percent 5:\", perc_fives)\n",
    "lengths = np.array(lengths)\n",
    "print(\"Mean length:\", np.mean(lengths))\n",
    "print(\"Stddev length:\", np.std(lengths))\n",
    "# OUTPUT OF THIS BLOCK:\n",
    "# ('Percent 1:', 13.64312871947628)\n",
    "# ('Percent 2:', 8.460983894496179)\n",
    "# ('Percent 3:', 11.975605302213054)\n",
    "# ('Percent 4:', 23.8934195220915)\n",
    "# ('Percent 5:', 42.026862561722986)\n",
    "# ('Mean length:', 113.77964893632742)\n",
    "# ('Stddev length:', 106.17315470136312)\n",
    "# ('Percent 1:', 12.967181927784615)\n",
    "# ('Percent 2:', 8.631450705325678)\n",
    "# ('Percent 3:', 12.348636328125826)\n",
    "# ('Percent 4:', 24.316263769211442)\n",
    "# ('Percent 5:', 41.73646726955244)\n",
    "# ('Mean length:', 114.77220862691111)\n",
    "# ('Stddev length:', 107.75916040435948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_utils.Net(vocab_size=vocab, \n",
    "                       hidden_dim=512, \n",
    "                       embed_dim=128, \n",
    "                       num_layers=1, \n",
    "                       num_classes=5, \n",
    "                       dropout=0.4, \n",
    "                       batch_size=BATCH_SIZE)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "# Lists to keep track of average train / test losses over time (for plotting)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "step_size = BATCH_SIZE if PAD_BATCH_FLAG else 1\n",
    "train_log_interval = len(dataset)/step_size/logs_per_epoch\n",
    "test_log_interval = len(test_dataset)/step_size/logs_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    # Training over all training data\n",
    "    print('EPOCH:', epoch)\n",
    "    if epoch < num_epochs/2:\n",
    "        lr = 1e-2\n",
    "    else:\n",
    "        lr = 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.7, 0.99))\n",
    "    train_loss.extend(lstm_utils.pass_through(model,\n",
    "                                              loss_fn,\n",
    "                                              optimizer,\n",
    "                                              dataset,\n",
    "                                              batch=PAD_BATCH_FLAG,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              train=True,\n",
    "                                              log_every=train_log_interval))\n",
    "    test_loss.extend(lstm_utils.pass_through(model,\n",
    "                                             loss_fn,\n",
    "                                             optimizer,\n",
    "                                             test_dataset,\n",
    "                                             batch=PAD_BATCH_FLAG,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             train=False,\n",
    "                                             log_every=test_log_interval))\n",
    "    # Checkpoint the model with the state_dict, optimizer, and current epoch number\n",
    "    lstm_utils.save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, filename='yelp_sentiment_epoch'+str(epoch+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, 'r', test_loss, 'b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
