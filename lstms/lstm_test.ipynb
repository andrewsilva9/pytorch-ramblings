{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lstm_utils\n",
    "import fclstm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "learning_rate = 1e-3\n",
    "running_loss = []\n",
    "BATCH_SIZE = 64\n",
    "# Use Fully Connected LSTM?:\n",
    "fc = True\n",
    "logs_per_epoch = 10\n",
    "num_epochs = 18\n",
    "# MAX\n",
    "_LEN = 500\n",
    "PAD_BATCH_FLAG = True\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "train_dir = '/home/asilva/Data/aclImdb/train'\n",
    "test_dir = '/home/asilva/Data/aclImdb/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, word_to_id = lstm_utils.build_dataset_imdb(train=True)\n",
    "vocab = len(word_to_id)\n",
    "test_dataset, word_to_id_t = lstm_utils.build_dataset_imdb(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946\n"
     ]
    }
   ],
   "source": [
    "print(word_to_id['alright'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for more efficient batching\n",
    "dataset.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "test_dataset.sort(key=lambda x: len(x[0]), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fc:\n",
    "    model = fclstm.FCLSTM(vocab_size=vocab,\n",
    "                           hidden_dim=512,\n",
    "                           embed_dim=128,\n",
    "                           num_layers=1,\n",
    "                           num_classes=2,\n",
    "                           dropout=0.4,\n",
    "                           batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    model = lstm_utils.Net(vocab_size=vocab,\n",
    "                           hidden_dim=512,\n",
    "                           embed_dim=128,\n",
    "                           num_layers=1,\n",
    "                           num_classes=2,\n",
    "                           dropout=0.4,\n",
    "                           batch_size=BATCH_SIZE)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of average train / test losses over time (for plotting)\n",
    "step_size = BATCH_SIZE if PAD_BATCH_FLAG else 1\n",
    "train_log_interval = len(dataset)/step_size/logs_per_epoch\n",
    "test_log_interval = len(test_dataset)/step_size/logs_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EPOCH:', 1)\n",
      "Step 78 || Avg Loss: 0.686623841524\n",
      "Step 156 || Avg Loss: 0.655509205965\n",
      "Step 234 || Avg Loss: 0.540639139521\n",
      "Step 312 || Avg Loss: 0.497603384348\n",
      "Step 390 || Avg Loss: 0.459023484626\n",
      "Step 468 || Avg Loss: 0.452339950662\n",
      "Step 546 || Avg Loss: 0.398510616941\n",
      "Step 624 || Avg Loss: 0.367069698297\n",
      "Step 702 || Avg Loss: 0.359581107321\n",
      "Step 780 || Avg Loss: 0.310864886699\n",
      "('EPOCH:', 2)\n",
      "Step 78 || Avg Loss: 0.329009207969\n",
      "Step 156 || Avg Loss: 0.292726625617\n",
      "Step 234 || Avg Loss: 0.253643899105\n",
      "Step 312 || Avg Loss: 0.279482502681\n",
      "Step 390 || Avg Loss: 0.265057143373\n",
      "Step 468 || Avg Loss: 0.271811715256\n",
      "Step 546 || Avg Loss: 0.254474552014\n",
      "Step 624 || Avg Loss: 0.252441881272\n",
      "Step 702 || Avg Loss: 0.244309995323\n",
      "Step 780 || Avg Loss: 0.213488490058\n",
      "('EPOCH:', 3)\n",
      "Step 78 || Avg Loss: 0.234360287157\n",
      "Step 156 || Avg Loss: 0.176823065306\n",
      "Step 234 || Avg Loss: 0.169407272377\n",
      "Step 312 || Avg Loss: 0.208312306386\n",
      "Step 390 || Avg Loss: 0.182757374448\n",
      "Step 468 || Avg Loss: 0.210277421997\n",
      "Step 546 || Avg Loss: 0.186646922635\n",
      "Step 624 || Avg Loss: 0.174900695252\n",
      "Step 702 || Avg Loss: 0.170422237653\n",
      "Step 780 || Avg Loss: 0.189869947015\n",
      "('EPOCH:', 4)\n",
      "Step 78 || Avg Loss: 0.172581211115\n",
      "Step 156 || Avg Loss: 0.125458476731\n",
      "Step 234 || Avg Loss: 0.120517831905\n",
      "Step 312 || Avg Loss: 0.137064113473\n",
      "Step 390 || Avg Loss: 0.14944506864\n",
      "Step 468 || Avg Loss: 0.160305497213\n",
      "Step 546 || Avg Loss: 0.139488718544\n",
      "Step 624 || Avg Loss: 0.126451694383\n",
      "Step 702 || Avg Loss: 0.137390790006\n",
      "Step 780 || Avg Loss: 0.132311924576\n",
      "('EPOCH:', 5)\n",
      "Step 78 || Avg Loss: 0.145784706809\n",
      "Step 156 || Avg Loss: 0.0985757465689\n",
      "Step 234 || Avg Loss: 0.0799134850311\n",
      "Step 312 || Avg Loss: 0.126519605565\n",
      "Step 390 || Avg Loss: 0.109587847972\n",
      "Step 468 || Avg Loss: 0.128321172502\n",
      "Step 546 || Avg Loss: 0.112601237037\n",
      "Step 624 || Avg Loss: 0.129961651463\n",
      "Step 702 || Avg Loss: 0.116763574453\n",
      "Step 780 || Avg Loss: 0.134698630788\n",
      "('EPOCH:', 6)\n",
      "Step 78 || Avg Loss: 0.119721295646\n",
      "Step 156 || Avg Loss: 0.0775098747884\n",
      "Step 234 || Avg Loss: 0.0754185780787\n",
      "Step 312 || Avg Loss: 0.131402960453\n",
      "Step 390 || Avg Loss: 0.122709577903\n",
      "Step 468 || Avg Loss: 0.13563836034\n",
      "Step 546 || Avg Loss: 0.111580832718\n",
      "Step 624 || Avg Loss: 0.110929505088\n",
      "Step 702 || Avg Loss: 0.125503145755\n",
      "Step 780 || Avg Loss: 0.132006104295\n",
      "('EPOCH:', 7)\n",
      "Step 78 || Avg Loss: 0.128553962717\n",
      "Step 156 || Avg Loss: 0.0694965866681\n",
      "Step 234 || Avg Loss: 0.0821461682566\n",
      "Step 312 || Avg Loss: 0.0811535251828\n",
      "Step 390 || Avg Loss: 0.0827047220933\n",
      "Step 468 || Avg Loss: 0.0811443964545\n",
      "Step 546 || Avg Loss: 0.0518575270827\n",
      "Step 624 || Avg Loss: 0.0411409865826\n",
      "Step 702 || Avg Loss: 0.0296960139575\n",
      "Step 780 || Avg Loss: 0.0202432426218\n",
      "('EPOCH:', 8)\n",
      "Step 78 || Avg Loss: 0.0682677023877\n",
      "Step 156 || Avg Loss: 0.0283976692157\n",
      "Step 234 || Avg Loss: 0.0358192603199\n",
      "Step 312 || Avg Loss: 0.0292361272881\n",
      "Step 390 || Avg Loss: 0.0304766925386\n",
      "Step 468 || Avg Loss: 0.0335653685511\n",
      "Step 546 || Avg Loss: 0.0197738004992\n",
      "Step 624 || Avg Loss: 0.0117845682618\n",
      "Step 702 || Avg Loss: 0.0107263772844\n",
      "Step 780 || Avg Loss: 0.01089033894\n",
      "('EPOCH:', 9)\n",
      "Step 78 || Avg Loss: 0.037571205877\n",
      "Step 156 || Avg Loss: 0.012003840795\n",
      "Step 234 || Avg Loss: 0.0154087541577\n",
      "Step 312 || Avg Loss: 0.0123964879805\n",
      "Step 390 || Avg Loss: 0.0125914035508\n",
      "Step 468 || Avg Loss: 0.0128291877321\n",
      "Step 546 || Avg Loss: 0.00795298325232\n",
      "Step 624 || Avg Loss: 0.00496373477225\n",
      "Step 702 || Avg Loss: 0.00400042304626\n",
      "Step 780 || Avg Loss: 0.00487535542403\n",
      "('EPOCH:', 10)\n",
      "Step 78 || Avg Loss: 0.0152415657082\n",
      "Step 156 || Avg Loss: 0.00587582222831\n",
      "Step 234 || Avg Loss: 0.00771331135184\n",
      "Step 312 || Avg Loss: 0.00380820336823\n",
      "Step 390 || Avg Loss: 0.00553899186735\n",
      "Step 468 || Avg Loss: 0.00511031384126\n",
      "Step 546 || Avg Loss: 0.00400606456857\n",
      "Step 624 || Avg Loss: 0.00196885308012\n",
      "Step 702 || Avg Loss: 0.00151491664255\n",
      "Step 780 || Avg Loss: 0.00145513898669\n",
      "('EPOCH:', 11)\n",
      "Step 78 || Avg Loss: 0.00827450742229\n",
      "Step 156 || Avg Loss: 0.00212432391559\n",
      "Step 234 || Avg Loss: 0.0028476768818\n",
      "Step 312 || Avg Loss: 0.00116778513751\n",
      "Step 390 || Avg Loss: 0.00168621499473\n",
      "Step 468 || Avg Loss: 0.00142182944677\n",
      "Step 546 || Avg Loss: 0.00137665669601\n",
      "Step 624 || Avg Loss: 0.000830219342158\n",
      "Step 702 || Avg Loss: 0.00038278570924\n",
      "Step 780 || Avg Loss: 0.000466564956766\n",
      "('EPOCH:', 12)\n",
      "Step 78 || Avg Loss: 0.00524122886455\n",
      "Step 156 || Avg Loss: 0.000671861669383\n",
      "Step 234 || Avg Loss: 0.00157964141227\n",
      "Step 312 || Avg Loss: 0.00032762853572\n",
      "Step 390 || Avg Loss: 0.000427490004744\n",
      "Step 468 || Avg Loss: 0.000298375932452\n",
      "Step 546 || Avg Loss: 0.00049140309103\n",
      "Step 624 || Avg Loss: 0.000197795219719\n",
      "Step 702 || Avg Loss: 9.0255569189e-05\n",
      "Step 780 || Avg Loss: 0.000109598422662\n",
      "('EPOCH:', 13)\n",
      "Step 78 || Avg Loss: 0.00295872566028\n",
      "Step 156 || Avg Loss: 0.000204694576752\n",
      "Step 234 || Avg Loss: 0.000231759574933\n",
      "Step 312 || Avg Loss: 0.000113504819381\n",
      "Step 390 || Avg Loss: 0.000171617246591\n",
      "Step 468 || Avg Loss: 0.000101093775951\n",
      "Step 546 || Avg Loss: 0.000194558109611\n",
      "Step 624 || Avg Loss: 6.21829755031e-05\n",
      "Step 702 || Avg Loss: 3.06662076559e-05\n",
      "Step 780 || Avg Loss: 3.97665187334e-05\n",
      "('EPOCH:', 14)\n",
      "Step 78 || Avg Loss: 0.00215259313774\n",
      "Step 156 || Avg Loss: 0.000279994108356\n",
      "Step 234 || Avg Loss: 0.000231339787252\n",
      "Step 312 || Avg Loss: 0.000131689346372\n",
      "Step 390 || Avg Loss: 8.71795301254e-05\n",
      "Step 468 || Avg Loss: 5.64995675515e-05\n",
      "Step 546 || Avg Loss: 0.000240851181726\n",
      "Step 624 || Avg Loss: 6.61797821522e-05\n",
      "Step 702 || Avg Loss: 1.97291374207e-05\n",
      "Step 780 || Avg Loss: 2.42047393933e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    # Training over all training data\n",
    "    print('EPOCH:', epoch)\n",
    "    if epoch < num_epochs/4:\n",
    "        lr = learning_rate\n",
    "    elif epoch < num_epochs/2:\n",
    "        lr = learning_rate * 0.5\n",
    "    else:\n",
    "        lr = learning_rate * 0.1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.7, 0.99))\n",
    "    train_loss.extend(lstm_utils.pass_through(model,\n",
    "                                              loss_fn,\n",
    "                                              optimizer,\n",
    "                                              dataset,\n",
    "                                              batch=PAD_BATCH_FLAG,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              train=True,\n",
    "                                              log_every=train_log_interval))\n",
    "    test_loss.extend(lstm_utils.pass_through(model,\n",
    "                                             loss_fn,\n",
    "                                             optimizer,\n",
    "                                             test_dataset,\n",
    "                                             batch=PAD_BATCH_FLAG,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             train=False,\n",
    "                                             log_every=test_log_interval))\n",
    "    # Checkpoint the model with the state_dict, optimizer, and current epoch number\n",
    "    lstm_utils.save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, filename='sentiment_epoch'+str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f135c211690>,\n",
       " <matplotlib.lines.Line2D at 0x7f13d247f1d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13bc0c2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, 'r', test_loss, 'b')\n",
    "# plt.plot(train_loss, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'savefig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2442620a202e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avgplot.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'savefig'"
     ]
    }
   ],
   "source": [
    "plt.savefig('avg_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
